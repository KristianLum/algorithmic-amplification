{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c6b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef74b05",
   "metadata": {},
   "source": [
    "# Simulating amplification metrics under biased historical algorithm\n",
    "\n",
    "Algorithmic amplification is difficult to define, partially because it is by its nature a relative metric-- we need to define amplification with respect to some baseline. Here, I look at how measures of algorithmic amplification are misleading if the baseline is the result of a biased algorithm previously. Specifically, suppose we have a population of _n_ accounts, all of which are \"identical\". That is, at each time point, each account draws a value from a N(0,1) and tweets it. The other accounts' preference is to see the _K_ accounts whose value is closest to theirs, with a slight preference for accounts they already follow. At each time point, they follow each account they have seen with probability _p_.  \n",
    "\n",
    "I consider three types of algorthms for determing which content they see: (1) a \"biased\" algorithm, in which the first _num_preferred_ accounts (the \"preferred users\") get a boost in their ranking, (2) a \"baseline\" algorithm, in which every account sees content according to their known preferences as described above, and (3) reverse chron. \n",
    "\n",
    "Our goal is to measure how much \"amplification\" the biased algorithm has, which we define as the number of impressions given to the preferred users under the biased algorithm divided by the number of impressions given to the preferred users under reverse chron. \n",
    "\n",
    "What happens if the the \"biased\" algorithm is used at first? And then, we measure amplification going forward.\n",
    "What happens if the \"baseline\" algorithm is used at first?\n",
    "\n",
    "How does this change what we conclude about algorithmic amplification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76d3bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "n = 100\n",
    "p = .05\n",
    "num_iter = 200\n",
    "K = 10\n",
    "follow_factor = 0.1\n",
    "follow_prob = 0.05\n",
    "num_preferred = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3fd613d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simulation:\n",
    "    def __init__(self, n):\n",
    "        self.follows = {key : [] for key in list(range(n))}\n",
    "        self.impressions = {key : [] for key in list(range(n))}\n",
    "        self.n = n\n",
    "        \n",
    "    def get_timeline_baseline(self, values, i, K, follow_factor):\n",
    "        follow_ind = np.zeros(self.n)\n",
    "        follow_ind[self.follows[i]] = 1\n",
    "        diff = np.abs(values[i] - values) - follow_factor*follow_ind\n",
    "        top_k =  sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "        top_k.remove(i)\n",
    "        return(top_k[0:K])\n",
    "    \n",
    "    def get_timeline_reverse_chron(self, values, i, K):\n",
    "        #automatically take all followers\n",
    "        top_k = self.follows[i]\n",
    "        random.shuffle(top_k)\n",
    "        #just switch back to an empty list in the case where top_k is empty\n",
    "        if not top_k:\n",
    "            top_k = []\n",
    "        if (len(top_k) < K):\n",
    "            diff = np.abs(values[i] - values)\n",
    "            top_k = top_k + sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "            top_k.remove(i)\n",
    "        top_k =  top_k[0:K] \n",
    "        return(top_k)\n",
    "        \n",
    "    def get_timeline_biased(self, values, i, K, follow_factor, num_preferred, preferred_factor):\n",
    "        follow_ind = np.zeros(self.n)\n",
    "        follow_ind[self.follows[i]] = 1\n",
    "        diff = np.abs(values[i] - values) - follow_factor*follow_ind\n",
    "        diff[0:num_preferred] -= preferred_factor\n",
    "        top_k =  sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "        top_k.remove(i)\n",
    "        return(top_k[:K])\n",
    "    \n",
    "    def run_simulation(self, num_iter, sim_type = \"baseline\",  K=10, follow_factor=0.1, \\\n",
    "                     follow_prob=0.05, num_preferred=10, preferred_factor=0.2, mu = 0):\n",
    "        for iter in range(num_iter):\n",
    "            #simulate values\n",
    "            values = np.random.normal(size=self.n, loc = mu)\n",
    "            for i in range(self.n):\n",
    "                if sim_type == \"baseline\":\n",
    "                    top_k = self.get_timeline_baseline(values, i, K, follow_factor)\n",
    "                if sim_type == \"biased\":\n",
    "                    top_k = self.get_timeline_biased(values, i, K, follow_factor, \\\n",
    "                                                      num_preferred, preferred_factor)\n",
    "                if sim_type == \"reverse_chron\":\n",
    "                    top_k = self.get_timeline_reverse_chron(values, i, K)\n",
    "                \n",
    "                #top_k.sort()\n",
    "                #print(top_k)\n",
    "                self.impressions[i].extend(top_k)\n",
    "                follows = [j for j in top_k if np.random.uniform()<follow_prob]\n",
    "                self.follows[i] = list(set(self.follows[i]).union(set(follows)))\n",
    "                #this is ugly, changing from list to set back to list, maybe can make this prettier?\n",
    "    \n",
    "    def erase_impression_history(self):\n",
    "        self.impressions = {key : [] for key in list(range(n))}\n",
    "      \n",
    "    def barplot_impression_counts(self, K=10, last_iters=5):\n",
    "        \n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        sn.barplot(x=num_impressions.index.values,y=num_impressions.values)\n",
    "\n",
    "    def histogram_impression_counts(self, K=10, last_iters=5):\n",
    "        print(K*last_iters)\n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        sn.histplot(num_impressions)\n",
    "    \n",
    "    def get_impressions_to_preferred(self, num_preferred=10, last_iters=5):\n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        preferred_impressions = num_impressions[num_impressions.index < num_preferred].sum()\n",
    "        return(preferred_impressions)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d1172c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_amplification(n, init_iter, init_algo, final_iter, final_algo_num,\\\n",
    "                      final_algo_denom, K=10, follow_factor = .1, follow_prob=0.05,  num_preferred=10,\\\n",
    "                         preferred_factor=0.2, mu=0, last_iters = 5, return_all=False):\n",
    "    \n",
    "        #initialize by running follow network forward init_iter iterations\n",
    "        sim_init = simulation(n)\n",
    "        sim_init.run_simulation(init_iter, init_algo, K, follow_factor,\\\n",
    "                                follow_prob, num_preferred, preferred_factor, mu)\n",
    "        sim_init.erase_impression_history()\n",
    "        \n",
    "        #copy initialized state\n",
    "        sim_final = simulation(n)\n",
    "        sim_final.follows = copy.deepcopy(sim_init.follows)\n",
    "        \n",
    "        \n",
    "        #run both forward from the same state\n",
    "        sim_init.run_simulation(final_iter, final_algo_num, K, follow_factor,\\\n",
    "                                follow_prob, num_preferred, preferred_factor, mu)\n",
    "        sim_final.run_simulation(final_iter, final_algo_denom, K, follow_factor,\\\n",
    "                                follow_prob, num_preferred, preferred_factor, mu)\n",
    "        \n",
    "        amplification = sim_init.get_impressions_to_preferred(num_preferred, last_iters)/\\\n",
    "            sim_final.get_impressions_to_preferred(num_preferred, last_iters)\n",
    "        if return_all:\n",
    "            return(sim_init, sim_final, amplification)\n",
    "        if not return_all:\n",
    "            return(amplification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5456116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.082995951417004"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#begin with biased algorithm, compare biased to reverse chron\n",
    "calculate_amplification(n, 50, \"biased\", 10, \"biased\", \"reverse_chron\", last_iters = 5, preferred_factor = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0bce4f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.875251509054326"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#begin with \"baseline\", compare biased to reverse chron\n",
    "calculate_amplification(n, 50, \"baseline\", 10, \"biased\", \"reverse_chron\", last_iters = 5, preferred_factor = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6c2aa5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.486973947895791"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#begin with \"reverse chron\", compare biased to reverse chron\n",
    "calculate_amplification(n, 50, \"reverse_chron\", 10, \"biased\", \"reverse_chron\", last_iters = 5, preferred_factor = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "39f6c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.134020618556701"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's try if different individuals have different means (those near the middle or around whom there is clustering have different preferences)\n",
    "#let's make 5 clusters of means. \n",
    "loc = [-10, -5, 0, 5, 10]*20\n",
    "mu = np.random.normal(size=n, loc=loc)\n",
    "mu.sort()\n",
    "\n",
    "sim_init, sim_final, amplification = calculate_amplification(n, 50, \"biased\", 1, \"biased\", \"reverse_chron\", \\\n",
    "                                                             preferred_factor = 3, mu=mu, return_all=True)\n",
    "amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e1a8618d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2613636363636362"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare to the case where we used a baseline algorithm before\n",
    "calculate_amplification(n, 50, \"baseline\", 1, \"biased\", \"reverse_chron\", \\\n",
    "                                                             preferred_factor = 3, mu=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd1679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
