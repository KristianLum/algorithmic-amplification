{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c6b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef74b05",
   "metadata": {},
   "source": [
    "# Simulating amplification metrics under biased historical algorithm\n",
    "\n",
    "Algorithmic amplification is difficult to define, partially because it is by its nature a relative metric-- we need to define amplification with respect to some baseline. Here, I look at how measures of algorithmic amplification are misleading if the baseline is the result of a biased algorithm previously. Specifically, suppose we have a population of _n_ accounts, all of which are \"identical\". That is, at each time point, each account draws a value from a N(0,1) and tweets it. The other accounts' preference is to see the _K_ accounts whose value is closest to theirs, with a slight preference for accounts they already follow. At each time point, they follow each accoun they have seen with probability _p_.  \n",
    "\n",
    "I consider three types of algorthms for determing which content they see: (1) a \"biased\" algorithm, in which the first _num_preferred_ accounts (the \"preferred users\") get a boost in their ranking, (2) a \"baseline\" algorithm, in which every account sees content according to their known preferences as described above, and (3) reverse chron. \n",
    "\n",
    "Our goal is to measure how much \"amplification\" the biased algorithm has, which we define as the number of impressions given to the preferred users under the biased algorithm divided by the number of impressions given to the preferred users under reverse chron. \n",
    "\n",
    "What happens if the the \"biased\" algorithm is used at first? And then, we measure amplification going forward.\n",
    "What happens if the \"baseline\" algorithm is used at first?\n",
    "\n",
    "How does this change what we conclude about algorithmic amplification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d3bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "n = 100\n",
    "p = .05\n",
    "num_iter = 200\n",
    "K = 10\n",
    "follow_factor = 0.1\n",
    "follow_prob = 0.05\n",
    "num_preferred = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd613d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simulation:\n",
    "    def __init__(self, n):\n",
    "        self.follows = {key : [] for key in list(range(n))}\n",
    "        self.impressions = {key : [] for key in list(range(n))}\n",
    "        self.n = n\n",
    "        \n",
    "    def get_timeline_baseline(self, values, i, K, follow_factor):\n",
    "        follow_ind = np.zeros(self.n)\n",
    "        follow_ind[self.follows[i]] = 1\n",
    "        diff = np.abs(values[i] - values) - follow_factor*follow_ind\n",
    "        top_k =  sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "        top_k.remove(i)\n",
    "        return(top_k[0:K])\n",
    "    \n",
    "    def get_timeline_reverse_chron(self, values, i, K):\n",
    "        #automatically take all followers\n",
    "        top_k = self.follows[i]\n",
    "        random.shuffle(top_k)\n",
    "        #just switch back to an empty list in the case where top_k is empty\n",
    "        if not top_k:\n",
    "            top_k = []\n",
    "        if (len(top_k) < K):\n",
    "            diff = np.abs(values[i] - values)\n",
    "            top_k = top_k + sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "            top_k.remove(i)\n",
    "        top_k =  top_k[0:K] #not behaving as expected, throwing in a bunch of random shit! \n",
    "        return(top_k)\n",
    "        \n",
    "    def get_timeline_biased(self, values, i, K, follow_factor, num_preferred, preferred_factor):\n",
    "        follow_ind = np.zeros(self.n)\n",
    "        follow_ind[self.follows[i]] = 1\n",
    "        diff = np.abs(values[i] - values) - follow_factor*follow_ind\n",
    "        diff[0:num_preferred] -= preferred_factor\n",
    "        top_k =  sorted(range(len(diff)), key = lambda sub: diff[sub])\n",
    "        top_k.remove(i)\n",
    "        return(top_k[:K])\n",
    "    \n",
    "    def run_simulation(self, num_iter, sim_type = \"baseline\",  K=10, follow_factor=0.1, \\\n",
    "                     follow_prob=0.05, num_preferred=10, preferred_factor=0.2):\n",
    "        for iter in range(num_iter):\n",
    "            #simulate values\n",
    "            values = np.random.normal(size=self.n)\n",
    "            for i in range(self.n):\n",
    "                if sim_type == \"baseline\":\n",
    "                    top_k = self.get_timeline_baseline(values, i, K, follow_factor)\n",
    "                if sim_type == \"biased\":\n",
    "                    top_k = self.get_timeline_biased(values, i, K, follow_factor, \\\n",
    "                                                      num_preferred, preferred_factor)\n",
    "                if sim_type == \"reverse_chron\":\n",
    "                    top_k = self.get_timeline_reverse_chron(values, i, K)\n",
    "                \n",
    "                #top_k.sort()\n",
    "                #print(top_k)\n",
    "                self.impressions[i].extend(top_k)\n",
    "                follows = [j for j in top_k if np.random.uniform()<follow_prob]\n",
    "                self.follows[i] = list(set(self.follows[i]).union(set(follows)))\n",
    "                #this is ugly, changing from list to set back to list, maybe can make this prettier?\n",
    "    \n",
    "    def erase_impression_history(self):\n",
    "        self.impressions = {key : [] for key in list(range(n))}\n",
    "      \n",
    "    def barplot_impression_counts(self, K=10, last_iters=5):\n",
    "        \n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        sn.barplot(x=num_impressions.index.values,y=num_impressions.values)\n",
    "\n",
    "    def histogram_impression_counts(self, K=10, last_iters=5):\n",
    "        print(K*last_iters)\n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        sn.histplot(num_impressions)\n",
    "    \n",
    "    def get_impressions_to_preferred(self, num_preferred=10, last_iters=5):\n",
    "        df = pd.DataFrame(self.impressions).tail(K*last_iters)\n",
    "        num_impressions = df.apply(lambda x: x.value_counts()).sum(axis=1)\n",
    "        preferred_impressions = num_impressions[num_impressions.index < num_preferred].sum()\n",
    "        return(preferred_impressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b085d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's initialize things by running the simulation for 50 iterations under the \"biased\" algorithm. \n",
    "sim_pref = simulation(n)\n",
    "sim_pref.run_simulation(50, \"biased\",K, follow_factor, follow_prob, num_preferred = 20, preferred_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d87761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the state of the follow graph after the initial period on which to run reverse chron going forward\n",
    "sim_pref_rc = simulation(n)\n",
    "sim_pref_rc.follows = copy.deepcopy(sim_pref.follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb2e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run both the biased algorithm and reverse chron for 10 iterations going forward\n",
    "sim_pref.run_simulation(10, \"biased\",K, follow_factor, follow_prob, num_preferred = 20, preferred_factor = 5)\n",
    "sim_pref_rc.run_simulation(10, \"reverse_chron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059ae432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amplification factor under a biased previous world is : 1.0018032458425166\n"
     ]
    }
   ],
   "source": [
    "#compare the number of impressions to the preferred peole under continuing with the preferred algo\n",
    "print(\"The amplification factor under a biased previous world is : \" + \n",
    "str(sim_pref.get_impressions_to_preferred(num_preferred=20, last_iters = 5)/\\\n",
    "sim_pref_rc.get_impressions_to_preferred(num_preferred=20, last_iters=5))\n",
    "     )\n",
    "\n",
    "#IT WORKSSSSSSS!!\n",
    "#note here that each user sees 10 accounts at each iteration and 15 users are preeferred by the algorithm. \n",
    "#i've set the preferred_factor, i.e. how biased the algo is in favor of those users, to be super high\n",
    "#this means in the biased algorithm users only ever see the preferred users, so their follow network only\n",
    "#ever contains preferred users. Thus, we'd expect amplification to be ~ 1. I've chosen these settings for now\n",
    "#so we can confirm this works, but we should fiddle with them for more compelling demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88bce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's compare to what we'd calculate amplification to be if the world had always been \"fair\", \n",
    "#i.e. we serve content according to the users true preferences\n",
    "\n",
    "#initialize simulation with 50 iterations of the baseline algorithm\n",
    "sim_baseline = simulation(n)\n",
    "sim_baseline.run_simulation(50, \"baseline\",K, follow_factor, follow_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e4665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the state of the follow graph after the initial period on which to run reverse chron going forward\n",
    "sim_baseline_rc = simulation(n)\n",
    "sim_baseline_rc.follows = copy.deepcopy(sim_baseline.follows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739f5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the pref one for 10 more iterations with pref algo\n",
    "sim_baseline.run_simulation(10, \"biased\",K, follow_factor, follow_prob, num_preferred = 20, preferred_factor = 5)\n",
    "sim_baseline_rc.run_simulation(10, \"reverse_chron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c852a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amplification factor under the baseline previous world is : 5.04887983706721\n"
     ]
    }
   ],
   "source": [
    "#then we'd say that the biased algo is has amplification factor...\n",
    "print(\"The amplification factor under the baseline previous world is : \" + \n",
    "\n",
    "str(sim_baseline.get_impressions_to_preferred(10,5)/sim_baseline_rc.get_impressions_to_preferred(10,5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SO IN THE CASE WHERE WE HAD THE BIASED PRIOR WORLD, WE MEASURE THE BIASED ALGORITHM AS CONTAINING NO BIAS.\n",
    "#HOWEVER, IF WE COULD HAVE COMPARED IT TO A TRUE NEUTRAL STATE, WE WOULD HAVE FOUND THAT IT HAD AMPLIFICATION FACTOR OF NEARLY 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99beefae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
